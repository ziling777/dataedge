#!/usr/bin/env python3
"""
ä¸º QuickSight å¯¼å‡ºè½¦è¾†é¥æµ‹æ•°æ®
ä» S3 Tables æŸ¥è¯¢æ•°æ®å¹¶å¯¼å‡ºä¸º CSV æ–‡ä»¶ä¾› QuickSight ä½¿ç”¨
"""

import sys
from pyspark.sql import SparkSession
from pyspark.sql.functions import *
from pyspark.sql.types import *

def main():
    if len(sys.argv) != 2:
        print("Usage: export_for_quicksight.py <s3_bucket_name>")
        sys.exit(1)
    
    s3_bucket = sys.argv[1]
    
    # åˆ›å»º Spark ä¼šè¯
    spark = SparkSession.builder \
        .appName("ExportForQuickSight") \
        .getOrCreate()
    
    # S3 Tables é…ç½®
    canbus_table = "gpdemo.greptime.canbus01"
    
    print(f"å¼€å§‹å¯¼å‡º QuickSight æ•°æ®...")
    
    try:
        # è¯»å– S3 Tables æ•°æ®
        df = spark.table(canbus_table)
        print(f"æˆåŠŸè¯»å–è¡¨: {canbus_table}")
        print(f"æ•°æ®è¡Œæ•°: {df.count()}")
        
        # 1. å¯¼å‡ºå…³é”®æŒ‡æ ‡æ±‡æ€»
        print("å¯¼å‡ºå…³é”®æŒ‡æ ‡æ±‡æ€»...")
        summary_df = df.agg(
            count("*").alias("total_records"),
            countDistinct("vin_id").alias("unique_vehicles"),
            round(avg("fuel_percentage"), 2).alias("avg_fuel_percentage"),
            round(avg("display_speed"), 2).alias("avg_speed"),
            sum(when(col("ress_power_low_flag") == True, 1).otherwise(0)).alias("low_power_alerts"),
            round(avg("fuel_cltc_mileage"), 2).alias("avg_cltc_mileage"),
            round(avg("target_soc"), 2).alias("avg_target_soc")
        )
        
        # è½¬æ¢ä¸ºé•¿æ ¼å¼ä¾¿äº QuickSight ä½¿ç”¨
        summary_long = summary_df.select(
            lit("æ€»è®°å½•æ•°").alias("metric_name"), col("total_records").cast("double").alias("metric_value")
        ).union(
            summary_df.select(lit("è½¦è¾†æ€»æ•°").alias("metric_name"), col("unique_vehicles").cast("double").alias("metric_value"))
        ).union(
            summary_df.select(lit("å¹³å‡ç‡ƒæ²¹ç™¾åˆ†æ¯”").alias("metric_name"), col("avg_fuel_percentage").alias("metric_value"))
        ).union(
            summary_df.select(lit("å¹³å‡é€Ÿåº¦").alias("metric_name"), col("avg_speed").alias("metric_value"))
        ).union(
            summary_df.select(lit("ä½ç”µé‡è­¦å‘Šæ¬¡æ•°").alias("metric_name"), col("low_power_alerts").cast("double").alias("metric_value"))
        ).union(
            summary_df.select(lit("å¹³å‡CLTCç»­èˆª").alias("metric_name"), col("avg_cltc_mileage").alias("metric_value"))
        ).union(
            summary_df.select(lit("å¹³å‡ç›®æ ‡SOC").alias("metric_name"), col("avg_target_soc").alias("metric_value"))
        )
        
        summary_path = f"s3://{s3_bucket}/quicksight-data/summary_metrics.csv"
        summary_long.coalesce(1).write.mode("overwrite").option("header", "true").csv(summary_path)
        print(f"å…³é”®æŒ‡æ ‡å¯¼å‡ºåˆ°: {summary_path}")
        
        # 2. å¯¼å‡ºé©¾é©¶æ¨¡å¼åˆ†å¸ƒ
        print("å¯¼å‡ºé©¾é©¶æ¨¡å¼åˆ†å¸ƒ...")
        driving_modes = df.groupBy("clean_mode", "road_mode").agg(
            count("*").alias("record_count"),
            round(avg("fuel_percentage"), 2).alias("avg_fuel"),
            round(avg("display_speed"), 2).alias("avg_speed")
        ).withColumn(
            "mode_description", 
            concat(lit("æ¸…æ´æ¨¡å¼"), col("clean_mode"), lit("-é“è·¯æ¨¡å¼"), col("road_mode"))
        ).orderBy(desc("record_count"))
        
        modes_path = f"s3://{s3_bucket}/quicksight-data/driving_modes.csv"
        driving_modes.coalesce(1).write.mode("overwrite").option("header", "true").csv(modes_path)
        print(f"é©¾é©¶æ¨¡å¼åˆ†å¸ƒå¯¼å‡ºåˆ°: {modes_path}")
        
        # 3. å¯¼å‡ºé€Ÿåº¦åˆ†å¸ƒ
        print("å¯¼å‡ºé€Ÿåº¦åˆ†å¸ƒ...")
        speed_dist = df.withColumn(
            "speed_category",
            when(col("display_speed") <= 20, "ä½é€Ÿ(â‰¤20km/h)")
            .when(col("display_speed") <= 40, "ä¸­ä½é€Ÿ(21-40km/h)")
            .when(col("display_speed") <= 60, "ä¸­é€Ÿ(41-60km/h)")
            .when(col("display_speed") <= 80, "ä¸­é«˜é€Ÿ(61-80km/h)")
            .when(col("display_speed") <= 100, "é«˜é€Ÿ(81-100km/h)")
            .otherwise("è¶…é«˜é€Ÿ(>100km/h)")
        ).groupBy("speed_category").agg(
            count("*").alias("record_count"),
            round(avg("fuel_percentage"), 2).alias("avg_fuel")
        ).orderBy(desc("record_count"))
        
        speed_path = f"s3://{s3_bucket}/quicksight-data/speed_distribution.csv"
        speed_dist.coalesce(1).write.mode("overwrite").option("header", "true").csv(speed_path)
        print(f"é€Ÿåº¦åˆ†å¸ƒå¯¼å‡ºåˆ°: {speed_path}")
        
        # 4. å¯¼å‡ºå……ç”µè¡Œä¸ºåˆ†æ
        print("å¯¼å‡ºå……ç”µè¡Œä¸ºåˆ†æ...")
        charging_behavior = df.withColumn(
            "charging_category",
            when(col("charging_time_remain_minute") == 0, "æ— éœ€å……ç”µ")
            .when(col("charging_time_remain_minute") <= 30, "å¿«é€Ÿå……ç”µ(â‰¤30åˆ†é’Ÿ)")
            .when(col("charging_time_remain_minute") <= 120, "æ ‡å‡†å……ç”µ(31-120åˆ†é’Ÿ)")
            .otherwise("é•¿æ—¶é—´å……ç”µ(>120åˆ†é’Ÿ)")
        ).groupBy("charging_category").agg(
            count("*").alias("session_count"),
            round(avg("target_soc"), 2).alias("avg_target_soc"),
            round(avg("fuel_percentage"), 2).alias("avg_fuel_at_charging")
        ).orderBy(desc("session_count"))
        
        charging_path = f"s3://{s3_bucket}/quicksight-data/charging_behavior.csv"
        charging_behavior.coalesce(1).write.mode("overwrite").option("header", "true").csv(charging_path)
        print(f"å……ç”µè¡Œä¸ºåˆ†æå¯¼å‡ºåˆ°: {charging_path}")
        
        # 5. å¯¼å‡ºæ—¶é—´åºåˆ—æ•°æ®ï¼ˆæŒ‰å°æ—¶èšåˆï¼‰
        print("å¯¼å‡ºæ—¶é—´åºåˆ—æ•°æ®...")
        time_series = df.withColumn("hour", date_trunc("hour", col("ts"))) \
            .groupBy("hour").agg(
                count("*").alias("record_count"),
                countDistinct("vin_id").alias("active_vehicles"),
                round(avg("fuel_percentage"), 2).alias("avg_fuel"),
                round(avg("display_speed"), 2).alias("avg_speed"),
                sum(when(col("ress_power_low_flag") == True, 1).otherwise(0)).alias("low_power_alerts")
            ).orderBy("hour")
        
        timeseries_path = f"s3://{s3_bucket}/quicksight-data/time_series.csv"
        time_series.coalesce(1).write.mode("overwrite").option("header", "true").csv(timeseries_path)
        print(f"æ—¶é—´åºåˆ—æ•°æ®å¯¼å‡ºåˆ°: {timeseries_path}")
        
        print("âœ… æ‰€æœ‰æ•°æ®å¯¼å‡ºå®Œæˆ!")
        print(f"QuickSight æ•°æ®æ–‡ä»¶ä¿å­˜åœ¨: s3://{s3_bucket}/quicksight-data/")
        
        # æ˜¾ç¤ºæ•°æ®é¢„è§ˆ
        print("\nğŸ“Š å…³é”®æŒ‡æ ‡é¢„è§ˆ:")
        summary_long.show(10, False)
        
        print("\nğŸ“ˆ é©¾é©¶æ¨¡å¼åˆ†å¸ƒé¢„è§ˆ:")
        driving_modes.show(5, False)
        
        print("\nğŸš— é€Ÿåº¦åˆ†å¸ƒé¢„è§ˆ:")
        speed_dist.show(10, False)
        
    except Exception as e:
        print(f"âŒ å¯¼å‡ºæ•°æ®æ—¶å‡ºé”™: {str(e)}")
        raise e
    
    finally:
        spark.stop()

if __name__ == "__main__":
    main()
